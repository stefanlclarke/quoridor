name: Quoridor

# dictates whether we are testing or not
play_quoridor: True
zero_critic : False

# parameters for the game
board_size: 3
number_of_walls: 1

# dimensions of the neural networks
actor_num_hidden: 3
actor_size_hidden: 64
critic_num_hidden: 3
critic_size_hidden: 64
softmax_regularizer: 0.9

# conv stuff
sidelen: 3
conv_internal_channels: 8
num_conv: 2
convolutional: False
conv_kernel_size: 1

# parameters relating to the actor playing the game
illegal_move_reward: -0.25
legal_move_reward: 0
win_reward: 1.
max_rounds_per_game: 40
epsilon: 0.4
epsilon_decay: 0.99
move_prob: 0.4
forward_prob: 0.4
move_prob_decay: 1.
gamma: 0.95
lambd: 0.5
minimum_epsilon: 0.1
minimum_move_prob: 0.4
cut_at_random_move: False
random_proportion: 0.4
win_speed_param: 2

# learning rates
learning_rate: 0.004
actor_learning_rate: 0.004
critic_learning_rate: 0.004
actor_weight_clip: 1000

# clipping
max_grad_norm: 10000.
entropy_constant: 0.003
entropy_bias: 1

# what am I training?
train_actor: True
train_critic: True
n_iterations_only_critic: 1000
iterations_only_actor_train: 0

# epoch parameters
games_between_backprops: 16
backprops_per_worker: 100
epochs: 10000000
save_every: 2
n_cores: 1
backwards_per_worker: 10
total_reset_every: Null
print_every: 3
decrease_epsilon_every: 10


# storage parameters
save_game_every: 100